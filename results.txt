Algorithm 1
A decision list improved by case folding and negation processing. No stopwords. 
Features: bag of words.
Chunk 0 : 48.80581516095535
Chunk 1 : 44.69616989148239
Chunk 2 : 47.18982535355523
Chunk 3 : 44.86314117263886
Chunk 4 : 44.54173452263841
Average score: 46.019337220254044

Algorithm 2
Naive bayes classifier with case folding and negation processing, no stopwords.
Features: bag of words, bigrams, trigrams, and 3-skipgrams.
Chunk 0 : 34.81652289495068
Chunk 1 : 35.838711116398024
Chunk 2 : 36.46889753453401
Chunk 3 : 33.76273718028721
Chunk 4 : 32.49182679933629
Average score: 34.67573910510124

Algorithm 3
A decision list improved by case folding and negation processing. No stopwords. 
Features: bag of words, bigrams, trigrams, and 3-skipgrams.
Chunk 0 : 42.23230814198954
Chunk 1 : 38.889775204928924
Chunk 2 : 39.38026405645345
Chunk 3 : 42.50515634023594
Chunk 4 : 41.112351000817576
Average score: 40.82397094888508

Algorithm 4
A combination of algorithms 2 and 3. The features are the same. 
To calculate a final answer, the decision list and naive bayes classifier vote. 
If they agree, that answer is chosen. 
If one classifier chooses positive/negative and the other chooses objective/neutral, 
positive/negative answer is chosen.
If one classifier chooses positive and the other chooses negative, the decision list
wins. (See above results.)
Chunk 0 : 45.06415590023787
Chunk 1 : 43.99844850992307
Chunk 2 : 44.10632032016915
Chunk 3 : 43.9641602044669
Chunk 4 : 46.20767853077984
Average score: 44.668152693115374

Algorithm 5
An extended decision list algorithm using the k most significant features as
opposed to just the most significant.
Features: bag of words, bigrams, trigrams, and 3-skipgrams.
k = 2
Chunk 0 : 44.20845526107807
Chunk 1 : 40.794369029663144
Chunk 2 : 39.592770162950764
Chunk 3 : 42.83606859671769
Chunk 4 : 43.52355922658157
Average score: 42.191044455398255374
k = 3
Chunk 0 : 42.48777780281044
Chunk 1 : 41.464174454828665
Chunk 2 : 39.85619980658454
Chunk 3 : 42.73142382731424
Chunk 4 : 41.813312208830794
Average score: 41.67057762007373
k = 4
Chunk 0 : 38.304946189436784
Chunk 1 : 34.91786958685913
Chunk 2 : 37.095118749254084
Chunk 3 : 38.75197768898662
Chunk 4 : 38.64014891740962
Average score: 37.54201222638925
As k increases, this algorithm actually performs worse.

Algorithm 6 
Same as algorithm 5 but uses bag of words as features.
k = 2
Chunk 0 : 38.304946189436784
Chunk 1 : 34.91786958685913
Chunk 2 : 37.095118749254084
Chunk 3 : 38.75197768898662
Chunk 4 : 38.64014891740962
Average score: 37.54201222638925

Algorithm 7
An SVM approach using LinearSVC from scikit-learn. 
For feature vectors, uses count vectors for bag of words (implemented by CountVectorizer).
Chunk 0 : 57.19184857877728
Chunk 1 : 51.80890948676947
Chunk 2 : 54.43067570727145
Chunk 3 : 53.99275473238431
Chunk 4 : 54.27702625895192
Average score: 54.340242952830884

Algorithm 8
An SVM approach using LinearSVC from scikit-learn. 
For feature vectors, uses occurrence vectors for bag of words.
NOT IMPLEMENTED

Algorithm 9
A k nearest neighbors approach using KNeighborsClassifier from scikit-learn.
For feature vectors, use count vectors for bag of words.
Uses weights for neighbors calculated by inverse of distance.
k = 5
Chunk 0 : 30.94296721325315
Chunk 1 : 29.765775138353057
Chunk 2 : 33.017053835027916
Chunk 3 : 29.22300222840583
Chunk 4 : 24.961180124223603
Average score: 29.581995707852705
Tends to guess objective a lot.

Algorithm 10
A k nearest neighbors approach using KNeighborsClassifier from scikit-learn.
For feature vectors, use count vectors for bag of words.
Uses uniform weights for neighbors.
k = 5
Chunk 0 : 26.9848439225133
Chunk 1 : 25.109345987208584
Chunk 2 : 32.81912925137584
Chunk 3 : 28.238505925420363
Chunk 4 : 24.48096885813149
Average score: 27.52655878892991
k = 15
Chunk 0 : 24.278248168519067
Chunk 1 : 25.407168010379017
Chunk 2 : 25.0166862196818
Chunk 3 : 23.830192332515814
Chunk 4 : 20.602517361780187
Average score: 23.826962418575178
Tends to guess objective a lot.

Algorithm 11
A combination of the count SVM (7) and bag-of-words decision list (1).
If they disagree, picks the non-neutral one.
If both are non-neutral, picks the SVM result.
Chunk 0 : 57.139846970355435
Chunk 1 : 51.80890948676947
Chunk 2 : 54.43067570727145
Chunk 3 : 53.965399109284
Chunk 4 : 54.27702625895192
Average score: 54.32437150652645

Algorithm 12
A weighted voting scheme between count SVM (7), bag-of-words decision list (1),
naive Bayes (2), and k nearest neighbors (9).
Calculates weights by looking at cross-validation scores of the individual
algorithms and then normalizing so that they sum to 1.
Chunk 0 : 56.92158814421589
Chunk 1 : 52.285145487833056
Chunk 2 : 54.765695965802834
Chunk 3 : 53.53357676335125
Chunk 4 : 53.675815680155054
Average score: 54.23636440827162

Algorithm 13
Same as algorithm 12 except KNN is omitted.
Chunk 0 : 56.99278267842823
Chunk 1 : 53.45457755804715
Chunk 2 : 54.97999729018548
Chunk 3 : 53.832156354167715
Chunk 4 : 54.121956817258976
Average score: 54.676294139617504